Perfect â€” thanks for the patience. I can see clearly now what you want:

You want a **complete, MCP-free, production-grade agentic setup** using:

* âœ… **Azure OpenAI**
* âœ… **AutoGen**
* âœ… **Pydantic schemas (single source of truth)**
* âœ… **Confluence tools (search + fetch)**
* âœ… **Strict response validation + retry**
* âœ… **Clean project structure**
* âŒ **No MCP**
* âŒ **No JSON-RPC / stdin/stdout**

Below is the **entire working skeleton** you can drop in and run.

---

# ðŸ“ Project Structure (Recommended)

```
confluence-agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ runner.py
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ confluence_fetch.py
â”‚   â”œâ”€â”€ confluence_search.py
â”‚
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ agent_response.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ azure_openai.py
â”‚   â”œâ”€â”€ env_setup.py
â”‚
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ response_guard.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.py
```

---

# 1ï¸âƒ£ Azure OpenAI Configuration

### `config/azure_openai.py`

```python
import os

AZURE_OPENAI_CONFIG = {
    "model": os.environ["AZURE_OPENAI_DEPLOYMENT"],
    "api_type": "azure",
    "api_base": os.environ["AZURE_OPENAI_ENDPOINT"],
    "api_key": os.environ["AZURE_OPENAI_API_KEY"],
    "api_version": "2024-02-15-preview",
}
```

---

### `config/env_setup.py`

```python
def init_env_and_session():
    required = [
        "AZURE_OPENAI_API_KEY",
        "AZURE_OPENAI_ENDPOINT",
        "AZURE_OPENAI_DEPLOYMENT",
    ]
    missing = [v for v in required if v not in __import__("os").environ]
    if missing:
        raise RuntimeError(f"Missing env vars: {missing}")
```

---

# 2ï¸âƒ£ Pydantic Schemas (SOURCE OF TRUTH)

### `schemas/agent_response.py`

```python
from typing import List, Optional, Literal
from pydantic import BaseModel, Field, HttpUrl


class Source(BaseModel):
    title: str
    url: HttpUrl
    page_id: Optional[str] = None
    space: Optional[str] = None


class Artifacts(BaseModel):
    summary: Optional[str] = None
    key_points: List[str] = Field(default_factory=list)
    extracted_entities: List[str] = Field(default_factory=list)


class AgentResponse(BaseModel):
    status: Literal["success", "partial", "error"]
    answer: str
    sources: List[Source] = Field(default_factory=list)
    artifacts: Optional[Artifacts] = None
    errors: List[str] = Field(default_factory=list)
```

---

# 3ï¸âƒ£ Confluence Tools

> These wrap your **existing internal APIs**
> (same logic you already had in MCP)

---

### `tools/confluence_fetch.py`

```python
from tool_utils.confluence_content_extractor import fetch_confluence_page


def confluence_fetch_page(url: str) -> dict:
    try:
        content = fetch_confluence_page(url)
        return {
            "url": url,
            "content": content
        }
    except Exception as e:
        return {
            "error": str(e),
            "url": url
        }
```

---

### `tools/confluence_search.py`

```python
from tool_utils.confluence_search import confluence_search


def confluence_search_pages(keywords: list[str], max_results: int = 5) -> dict:
    try:
        results = confluence_search(
            keywords=keywords,
            max_results=max_results
        )
        return {"results": results}
    except Exception as e:
        return {
            "error": str(e),
            "keywords": keywords
        }
```

---

# 4ï¸âƒ£ Agent Response Validation + Auto-Repair

### `validation/response_guard.py`

```python
import json
from pydantic import ValidationError
from schemas.agent_response import AgentResponse


def parse_and_validate(raw: str) -> AgentResponse:
    try:
        data = json.loads(raw)
        return AgentResponse.model_validate(data)
    except (json.JSONDecodeError, ValidationError) as e:
        raise RuntimeError(f"Schema validation failed: {e}")
```

---

# 5ï¸âƒ£ AutoGen Agent Setup (Azure OpenAI)

### `agent/agent.py`

```python
import autogen
from config.azure_openai import AZURE_OPENAI_CONFIG
from tools.confluence_fetch import confluence_fetch_page
from tools.confluence_search import confluence_search_pages

SYSTEM_MESSAGE = """
You are a Confluence knowledge assistant.

You MUST return your final response as VALID JSON
that can be parsed into the following Pydantic model:

AgentResponse {
  status: "success" | "partial" | "error"
  answer: string
  sources: list
  artifacts: object | null
  errors: list
}

Rules:
- JSON ONLY
- No markdown
- No commentary outside JSON
- Missing values must be empty lists or null
"""

assistant = autogen.AssistantAgent(
    name="confluence_agent",
    system_message=SYSTEM_MESSAGE,
    llm_config=AZURE_OPENAI_CONFIG,
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    code_execution_config=False,
)

user_proxy.register_function(
    function_map={
        "confluence_fetch_page": confluence_fetch_page,
        "confluence_search_pages": confluence_search_pages,
    }
)
```

---

# 6ï¸âƒ£ Guarded Execution (Retries + Repair)

### `agent/runner.py`

```python
from validation.response_guard import parse_and_validate


def run_with_guard(user_proxy, agent, message, retries=2):
    last_error = None

    for _ in range(retries + 1):
        chat = user_proxy.initiate_chat(
            agent,
            message=message,
        )

        try:
            return parse_and_validate(chat.summary)
        except RuntimeError as e:
            last_error = str(e)
            message = f"""
Your previous response was INVALID.

Error:
{last_error}

Fix your response so it EXACTLY matches the schema.
"""

    raise RuntimeError(last_error)
```

---

# 7ï¸âƒ£ Entry Point

### `main.py`

```python
from config.env_setup import init_env_and_session
from agent.agent import assistant, user_proxy
from agent.runner import run_with_guard

init_env_and_session()

if __name__ == "__main__":
    response = run_with_guard(
        user_proxy,
        assistant,
        message=(
            "Search Confluence for 'MCP architecture' and "
            "summarize the most relevant page."
        )
    )

    print(response.model_dump_json(indent=2))
```

---

# 8ï¸âƒ£ requirements.txt

```txt
pyautogen
pydantic>=2.6
openai
```

---

# âœ… What You Now Have

* âœ” Azure OpenAI wired correctly
* âœ” AutoGen agentic reasoning
* âœ” Tool invocation
* âœ” Strict Pydantic validation
* âœ” Automatic repair loop
* âœ” No MCP
* âœ” No JSON-RPC
* âœ” Clean, extensible architecture

---

## Want next?

I can:

* Add **planner/executor agents**
* Add **streaming structured output**
* Convert to **FastAPI**
* Add **RAG ingestion**
* Add **LangGraph compatibility**

Just tell me the next step ðŸ‘‡
